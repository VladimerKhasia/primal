{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ff5abdd",
   "metadata": {},
   "source": [
    "Unlike the paper, the code calculates primes dynamically instead of using a lookup table.\n",
    "This code generates Figure 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f6b26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code contains dynamic version of our method and it's backward and forward capabilities and adventages. \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on: {device}\")\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ==========================================\n",
    "# 1. HELPER FUNCTIONS\n",
    "# ==========================================\n",
    "\n",
    "def get_first_n_primes(n):\n",
    "    if n < 1: return torch.tensor([], device=device)\n",
    "    if n == 1: return torch.tensor([2.0], device=device)\n",
    "    if n < 6:\n",
    "        limit = 13\n",
    "    else:\n",
    "        log_n = math.log(n)\n",
    "        limit = int(n * (log_n + math.log(log_n))) + 3\n",
    "    sieve = np.ones(limit // 2, dtype=bool)\n",
    "    sieve[0] = False\n",
    "    cross_limit = int((math.isqrt(limit) - 1) / 2)\n",
    "    for i in range(1, cross_limit + 1):\n",
    "        if sieve[i]:\n",
    "            start_idx = 2 * i * (i + 1) + i\n",
    "            step = 2 * i + 1\n",
    "            sieve[start_idx::step] = False\n",
    "    prime_indices = np.nonzero(sieve)[0]\n",
    "    primes = 2 * prime_indices + 1\n",
    "    result = np.empty(len(primes) + 1, dtype=np.float32)\n",
    "    result[0] = 2.0\n",
    "    result[1:] = primes\n",
    "    return torch.from_numpy(result[:n]).to(device)\n",
    "\n",
    "def calculate_metrics(vectors, batch_size=2000):\n",
    "    n, d = vectors.shape\n",
    "    vectors = torch.nn.functional.normalize(vectors, p=2, dim=1)\n",
    "    sum_sq = 0\n",
    "    max_coh = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    gram = torch.mm(vectors, vectors.t())\n",
    "    mask = ~torch.eye(n, dtype=bool, device=vectors.device)\n",
    "    off_diag = gram[mask]\n",
    "    \n",
    "    if off_diag.numel() > 0:\n",
    "        sum_sq = (off_diag ** 2).sum().item()\n",
    "        max_coh = off_diag.abs().max().item()\n",
    "        count = off_diag.numel()\n",
    "        \n",
    "    rms = math.sqrt(sum_sq / count) if count > 0 else 0\n",
    "    return rms, max_coh\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATA GENERATORS\n",
    "# ==========================================\n",
    "\n",
    "def generate_spiral(n_points=1000, noise=0.0):\n",
    "    n = torch.sqrt(torch.rand(n_points)) * 780 * (2 * math.pi / 360)\n",
    "    d1x = -torch.cos(n) * n + torch.randn(n_points) * noise\n",
    "    d1y = torch.sin(n) * n + torch.randn(n_points) * noise\n",
    "    return torch.stack([d1x, d1y], dim=1).to(device)\n",
    "\n",
    "def generate_circles(n_points=1000, noise=0.0):\n",
    "    linspace = torch.linspace(0, 2*math.pi, n_points // 2)\n",
    "    x1 = torch.cos(linspace) * 5 + torch.randn(n_points // 2) * noise\n",
    "    y1 = torch.sin(linspace) * 5 + torch.randn(n_points // 2) * noise\n",
    "    x2 = torch.cos(linspace) * 10 + torch.randn(n_points // 2) * noise\n",
    "    y2 = torch.sin(linspace) * 10 + torch.randn(n_points // 2) * noise\n",
    "    c1 = torch.stack([x1, y1], dim=1)\n",
    "    c2 = torch.stack([x2, y2], dim=1)\n",
    "    return torch.cat([c1, c2], dim=0).to(device)\n",
    "\n",
    "# ==========================================\n",
    "# 3. MODEL CLASS\n",
    "# ==========================================\n",
    "\n",
    "# class DynamicPrime(nn.Module):\n",
    "#     def __init__(self, input_dim, output_dim, scaling_factor=0.01):\n",
    "#         super().__init__()\n",
    "#         if output_dim % 2 != 0: raise ValueError(\"Output dimension must be even.\") \n",
    "#         self.input_dim = input_dim\n",
    "#         self.output_dim = output_dim\n",
    "#         self.half_dim = output_dim // 2\n",
    "#         self.scaling_factor = scaling_factor\n",
    "        \n",
    "#         num_primes_needed = self.half_dim * input_dim\n",
    "#         primes = get_first_n_primes(num_primes_needed)\n",
    "#         self.register_buffer(\"weights\", torch.sqrt(primes).reshape(self.half_dim, input_dim))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         self.projection = torch.mm(x, self.weights.t()) * 2 * math.pi * self.scaling_factor\n",
    "#         return torch.cat([torch.cos(self.projection), torch.sin(self.projection)], dim=-1)\n",
    "\n",
    "#     def reverse(self, y):\n",
    "#         cos_part = y[:, :self.half_dim]\n",
    "#         sin_part = y[:, self.half_dim:]\n",
    "#         recovered_phases = torch.atan2(sin_part, cos_part) \n",
    "        \n",
    "#         effective_W_T = self.weights.t() * 2 * math.pi * self.scaling_factor\n",
    "#         W_inv = torch.linalg.pinv(effective_W_T)\n",
    "        \n",
    "#         x_hat = torch.mm(recovered_phases, W_inv) \n",
    "#         return x_hat\n",
    "\n",
    "class DynamicPrime(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, scaling_factor=0.01):\n",
    "        super().__init__()\n",
    "        if output_dim % 2 != 0: raise ValueError(\"Output dimension must be even.\") \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.half_dim = output_dim // 2\n",
    "        self.scaling_factor = scaling_factor\n",
    "        \n",
    "        num_primes_needed = self.half_dim * input_dim\n",
    "        primes = get_first_n_primes(num_primes_needed)\n",
    "        \n",
    "        # Store as float32 to save memory (Standard PyTorch default)\n",
    "        # We will cast to double only during calculation\n",
    "        self.register_buffer(\"weights\", torch.sqrt(primes).reshape(self.half_dim, input_dim).float())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. Cast Input and Weights to Double\n",
    "        x_double = x.double() \n",
    "        weights_double = self.weights.double()\n",
    "        \n",
    "        # 2. High Precision Projection\n",
    "        # Performing matrix multiplication and scaling in float64 prevents \n",
    "        # phase information loss when values become large.\n",
    "        projection = torch.mm(x_double, weights_double.t()) * (2 * math.pi * self.scaling_factor)\n",
    "        \n",
    "        # 3. Cast back to float (or input type) for output to save memory in next layers\n",
    "        # Note: cos/sin are computed on double precision inputs, then cast down.\n",
    "        return torch.cat([torch.cos(projection), torch.sin(projection)], dim=-1).type_as(x)\n",
    "\n",
    "    def reverse(self, y):\n",
    "        # 1. Cast input to double to preserve phase accuracy during atan2\n",
    "        y_double = y.double()\n",
    "        \n",
    "        cos_part = y_double[:, :self.half_dim]\n",
    "        sin_part = y_double[:, self.half_dim:]\n",
    "        recovered_phases = torch.atan2(sin_part, cos_part) \n",
    "        \n",
    "        # 2. Recalculate Transformation Matrix in Double\n",
    "        # Inverting matrices is very sensitive to precision. Doing this in double \n",
    "        # drastically reduces reconstruction error.\n",
    "        weights_double = self.weights.double()\n",
    "        effective_W_T = weights_double.t() * (2 * math.pi * self.scaling_factor)\n",
    "        \n",
    "        # 3. High Precision Pseudo-Inverse\n",
    "        W_inv = torch.linalg.pinv(effective_W_T)\n",
    "        \n",
    "        # 4. Reconstruct and cast back to float\n",
    "        x_hat = torch.mm(recovered_phases, W_inv) \n",
    "        return x_hat.float()\n",
    "\n",
    "# ==========================================\n",
    "# 4. EXPERIMENT EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "def run_experiment():\n",
    "    n_points = 1000\n",
    "    noise_levels = [0.0, 0.5, 1.5] \n",
    "    patterns = ['Spiral', 'Circles']\n",
    "    l_scl = 0.007\n",
    "    h_scl = 1.0\n",
    "    scecial_scl = 0.02\n",
    "    \n",
    "    model_low = DynamicPrime(input_dim=2, output_dim=4, scaling_factor=l_scl).to(device)\n",
    "    model_high = DynamicPrime(input_dim=2, output_dim=4, scaling_factor=h_scl).to(device)\n",
    "    model_high_128 = DynamicPrime(input_dim=2, output_dim=128, scaling_factor=scecial_scl).to(device)\n",
    "    \n",
    "    rows = len(patterns) * len(noise_levels)\n",
    "    cols = 7 \n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(28, 4.0 * rows))\n",
    "    plt.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "    \n",
    "    row_idx = 0\n",
    "    \n",
    "    for pattern_name in patterns:\n",
    "        for noise in noise_levels:\n",
    "            # [Data Generation and Model Processing code remains the same...]\n",
    "            if pattern_name == 'Spiral':\n",
    "                data = generate_spiral(n_points, noise)\n",
    "            else:\n",
    "                data = generate_circles(n_points, noise)\n",
    "            \n",
    "            X_np = data.cpu().numpy()\n",
    "            \n",
    "            # ... (Low model processing) ...\n",
    "            with torch.no_grad():\n",
    "                y_low = model_low(data)\n",
    "                rms_low, coh_low = calculate_metrics(y_low)\n",
    "                x_recon_low = model_low.reverse(y_low)\n",
    "                mse_low = torch.nn.functional.mse_loss(x_recon_low, data).item()\n",
    "            pca_low = PCA(n_components=2, random_state=42)\n",
    "            y_low_viz = pca_low.fit_transform(y_low.cpu().numpy())\n",
    "            x_low_recon_np = x_recon_low.cpu().numpy()\n",
    "\n",
    "            # ... (High Dim 4 model processing) ...\n",
    "            with torch.no_grad():\n",
    "                y_high = model_high(data)\n",
    "                rms_high, coh_high = calculate_metrics(y_high)\n",
    "                x_recon_high = model_high.reverse(y_high)\n",
    "                mse_high = torch.nn.functional.mse_loss(x_recon_high, data).item()\n",
    "            pca_high = PCA(n_components=2, random_state=42)\n",
    "            y_high_viz = pca_high.fit_transform(y_high.cpu().numpy())\n",
    "            x_high_recon_np = x_recon_high.cpu().numpy()\n",
    "\n",
    "            # ... (High Dim 128 model processing) ...\n",
    "            with torch.no_grad():\n",
    "                y_128 = model_high_128(data)\n",
    "                rms_128, coh_128 = calculate_metrics(y_128)\n",
    "                x_recon_128 = model_high_128.reverse(y_128)\n",
    "                mse_128 = torch.nn.functional.mse_loss(x_recon_128, data).item()\n",
    "            pca_128 = PCA(n_components=2, random_state=42)\n",
    "            y_128_viz = pca_128.fit_transform(y_128.cpu().numpy())\n",
    "            x_128_recon_np = x_recon_128.cpu().numpy()\n",
    "\n",
    "            # ==========================================\n",
    "            # PLOTTING\n",
    "            # ==========================================\n",
    "            ax = axes[row_idx]\n",
    "\n",
    "            for sub_ax in ax:\n",
    "                sub_ax.set_box_aspect(1)\n",
    "            \n",
    "            # 1. Original\n",
    "            ax[0].scatter(X_np[:,0], X_np[:,1], s=2, c='blue', alpha=0.5)\n",
    "            ax[0].set_title(f\"INPUT\\n{pattern_name} (Noise={noise})\")\n",
    "            ax[0].axis('equal') # This keeps data square, set_box_aspect keeps frame square\n",
    "\n",
    "            # 2. Low Scale Latent\n",
    "            ax[1].scatter(y_low_viz[:,0], y_low_viz[:,1], s=2, c='red', alpha=0.5)\n",
    "            ax[1].set_title(f\"LATENT (Scale {l_scl})\\nRMS: {rms_low:.4f}, MaxCoh: {coh_low:.4f}\")\n",
    "            ax[1].set_xticks([]); ax[1].set_yticks([])\n",
    "\n",
    "            # 3. Low Scale Recon\n",
    "            ax[2].scatter(x_low_recon_np[:,0], x_low_recon_np[:,1], s=2, c='red', alpha=0.5)\n",
    "            ax[2].set_title(f\"RECON (Scale {l_scl})\\nMSE: {mse_low:.6f}\")\n",
    "            ax[2].axis('equal')\n",
    "\n",
    "            # 4. High Scale Latent (Dim 4)\n",
    "            ax[3].scatter(y_high_viz[:,0], y_high_viz[:,1], s=2, c='purple', alpha=0.5)\n",
    "            ax[3].set_title(f\"LATENT (High, Dim 4)\\nRMS: {rms_high:.4f}, MaxCoh: {coh_high:.4f}\")\n",
    "            ax[3].set_xticks([]); ax[3].set_yticks([])\n",
    "\n",
    "            # 5. High Scale Recon (Dim 4)\n",
    "            ax[4].scatter(x_high_recon_np[:,0], x_high_recon_np[:,1], s=2, c='purple', alpha=0.5)\n",
    "            ax[4].set_title(f\"RECON (High, Dim 4)\\nMSE: {mse_high:.6f}\")\n",
    "            ax[4].axis('equal')\n",
    "\n",
    "            # 6. High Scale Latent (Dim 128)\n",
    "            ax[5].scatter(y_128_viz[:,0], y_128_viz[:,1], s=2, c='magenta', alpha=0.5)\n",
    "            ax[5].set_title(f\"LATENT (High, Dim 128)\\nRMS: {rms_128:.4f}, MaxCoh: {coh_128:.4f}\")\n",
    "            ax[5].set_xticks([]); ax[5].set_yticks([])\n",
    "\n",
    "            # 7. High Scale Recon (Dim 128)\n",
    "            ax[6].scatter(x_128_recon_np[:,0], x_128_recon_np[:,1], s=2, c='magenta', alpha=0.5)\n",
    "            ax[6].set_title(f\"RECON (High, Dim 128)\\nMSE: {mse_128:.6f}\")\n",
    "            ax[6].axis('equal')\n",
    "            \n",
    "            row_idx += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    seed_everything(42)\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    run_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
