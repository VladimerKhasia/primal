{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f6f2f74",
   "metadata": {},
   "source": [
    "Unlike the paper, the code calculates primes dynamically instead of using a lookup table.\n",
    "This code generates Figures 4 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c658c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representation and Classification abilities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# SETUP\n",
    "# ==========================================\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on: {device}\")\n",
    "\n",
    "# ==========================================\n",
    "# HELPER FUNCTIONS & GENERATORS\n",
    "# ==========================================\n",
    "def get_first_n_primes(n):\n",
    "    if n < 1: return torch.tensor([], device=device)\n",
    "    if n == 1: return torch.tensor([2.0], device=device)\n",
    "    if n < 6:\n",
    "        limit = 13\n",
    "    else:\n",
    "        log_n = math.log(n)\n",
    "        limit = int(n * (log_n + math.log(log_n))) + 3\n",
    "    sieve = np.ones(limit // 2, dtype=bool)\n",
    "    sieve[0] = False\n",
    "    cross_limit = int((math.isqrt(limit) - 1) / 2)\n",
    "    for i in range(1, cross_limit + 1):\n",
    "        if sieve[i]:\n",
    "            start_idx = 2 * i * (i + 1) + i\n",
    "            step = 2 * i + 1\n",
    "            sieve[start_idx::step] = False\n",
    "    prime_indices = np.nonzero(sieve)[0]\n",
    "    primes = 2 * prime_indices + 1\n",
    "    result = np.empty(len(primes) + 1, dtype=np.float32)\n",
    "    result[0] = 2.0\n",
    "    result[1:] = primes\n",
    "    return torch.from_numpy(result[:n]).to(device)\n",
    "\n",
    "def generate_spiral(n_points=1000, noise=0.0):\n",
    "    n = torch.sqrt(torch.rand(n_points)) * 780 * (2 * math.pi / 360)\n",
    "    d1x = -torch.cos(n) * n + torch.randn(n_points) * noise\n",
    "    d1y = torch.sin(n) * n + torch.randn(n_points) * noise\n",
    "    return torch.stack([d1x, d1y], dim=1).to(device)\n",
    "\n",
    "def generate_circles(n_points=1000, noise=0.0):\n",
    "    linspace = torch.linspace(0, 2*math.pi, n_points // 2)\n",
    "    x1 = torch.cos(linspace) * 5 + torch.randn(n_points // 2) * noise\n",
    "    y1 = torch.sin(linspace) * 5 + torch.randn(n_points // 2) * noise\n",
    "    x2 = torch.cos(linspace) * 10 + torch.randn(n_points // 2) * noise\n",
    "    y2 = torch.sin(linspace) * 10 + torch.randn(n_points // 2) * noise\n",
    "    c1 = torch.stack([x1, y1], dim=1)\n",
    "    c2 = torch.stack([x2, y2], dim=1)\n",
    "    return torch.cat([c1, c2], dim=0).to(device)\n",
    "\n",
    "# ==========================================\n",
    "# MODEL CLASS\n",
    "# ==========================================\n",
    "# class DynamicPrime(nn.Module):\n",
    "#     def __init__(self, input_dim, output_dim, scaling_factor=0.01):\n",
    "#         super().__init__()\n",
    "#         if output_dim % 2 != 0: raise ValueError(\"Output dimension must be even.\") \n",
    "#         self.input_dim = input_dim\n",
    "#         self.output_dim = output_dim\n",
    "#         self.half_dim = output_dim // 2\n",
    "#         self.scaling_factor = scaling_factor\n",
    "        \n",
    "#         num_primes_needed = self.half_dim * input_dim\n",
    "#         primes = get_first_n_primes(num_primes_needed)\n",
    "#         self.register_buffer(\"weights\", torch.sqrt(primes).reshape(self.half_dim, input_dim))\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         self.projection = torch.mm(x, self.weights.t()) * 2 * math.pi * self.scaling_factor\n",
    "#         return torch.cat([torch.cos(self.projection), torch.sin(self.projection)], dim=-1)\n",
    "\n",
    "#     def reverse(self, y):\n",
    "#         cos_part = y[:, :self.half_dim]\n",
    "#         sin_part = y[:, self.half_dim:]\n",
    "#         recovered_phases = torch.atan2(sin_part, cos_part) \n",
    "        \n",
    "#         effective_W_T = self.weights.t() * 2 * math.pi * self.scaling_factor\n",
    "#         W_inv = torch.linalg.pinv(effective_W_T)\n",
    "        \n",
    "#         x_hat = torch.mm(recovered_phases, W_inv) \n",
    "#         return x_hat\n",
    "\n",
    "class DynamicPrime(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, scaling_factor=0.01):\n",
    "        super().__init__()\n",
    "        if output_dim % 2 != 0: raise ValueError(\"Output dimension must be even.\") \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.half_dim = output_dim // 2\n",
    "        self.scaling_factor = scaling_factor\n",
    "        \n",
    "        num_primes_needed = self.half_dim * input_dim\n",
    "        primes = get_first_n_primes(num_primes_needed)\n",
    "        \n",
    "        # Store as float32 to save memory (Standard PyTorch default)\n",
    "        # We will cast to double only during calculation\n",
    "        self.register_buffer(\"weights\", torch.sqrt(primes).reshape(self.half_dim, input_dim).float())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. Cast Input and Weights to Double\n",
    "        x_double = x.double() \n",
    "        weights_double = self.weights.double()\n",
    "        \n",
    "        # 2. High Precision Projection\n",
    "        # Performing matrix multiplication and scaling in float64 prevents \n",
    "        # phase information loss when values become large.\n",
    "        projection = torch.mm(x_double, weights_double.t()) * (2 * math.pi * self.scaling_factor)\n",
    "        \n",
    "        # 3. Cast back to float (or input type) for output to save memory in next layers\n",
    "        # Note: cos/sin are computed on double precision inputs, then cast down.\n",
    "        return torch.cat([torch.cos(projection), torch.sin(projection)], dim=-1).type_as(x)\n",
    "\n",
    "    def reverse(self, y):\n",
    "        # 1. Cast input to double to preserve phase accuracy during atan2\n",
    "        y_double = y.double()\n",
    "        \n",
    "        cos_part = y_double[:, :self.half_dim]\n",
    "        sin_part = y_double[:, self.half_dim:]\n",
    "        recovered_phases = torch.atan2(sin_part, cos_part) \n",
    "        \n",
    "        # 2. Recalculate Transformation Matrix in Double\n",
    "        # Inverting matrices is very sensitive to precision. Doing this in double \n",
    "        # drastically reduces reconstruction error.\n",
    "        weights_double = self.weights.double()\n",
    "        effective_W_T = weights_double.t() * (2 * math.pi * self.scaling_factor)\n",
    "        \n",
    "        # 3. High Precision Pseudo-Inverse\n",
    "        W_inv = torch.linalg.pinv(effective_W_T)\n",
    "        \n",
    "        # 4. Reconstruct and cast back to float\n",
    "        x_hat = torch.mm(recovered_phases, W_inv) \n",
    "        return x_hat.float()\n",
    "        \n",
    "# ==========================================\n",
    "# EXPERIMENT (3 SCALES)\n",
    "# ==========================================\n",
    "\n",
    "def run_extended_experiment():\n",
    "    print(\"Running Extended Similarity Experiment (Scales: 0.007, 0.02, 1.0)...\")\n",
    "    \n",
    "    # 1. Define Scales including the Full Reconstruction case\n",
    "    scales = [0.007, 0.02, 1.0] \n",
    "    dim = 4\n",
    "    n_points = 1000\n",
    "    \n",
    "    # 2. Generate Data\n",
    "    d1_spiral_clean = generate_spiral(n_points, noise=0.0)\n",
    "    d2_spiral_noisy = generate_spiral(n_points, noise=1.5)\n",
    "    d3_circle_clean = generate_circles(n_points, noise=0.0)\n",
    "    d4_circle_noisy = generate_circles(n_points, noise=1.5)\n",
    "    \n",
    "    datasets = [d1_spiral_clean, d2_spiral_noisy, d3_circle_clean, d4_circle_noisy]\n",
    "    labels = [\"Sp(C)\", \"Sp(N)\", \"Ci(C)\", \"Ci(N)\"]\n",
    "    full_labels = [\"Spiral (Clean)\", \"Spiral (Noisy)\", \"Circles (Clean)\", \"Circles (Noisy)\"]\n",
    "    \n",
    "    # 3. Setup Visualization\n",
    "    # Increased height to accommodate 3 rows\n",
    "    fig = plt.figure(figsize=(20, 18))\n",
    "    subfigs = fig.subfigures(3, 1, hspace=0.15)\n",
    "\n",
    "    for idx, scl in enumerate(scales):\n",
    "        # Initialize Model\n",
    "        model = DynamicPrime(input_dim=2, output_dim=dim, scaling_factor=scl).to(device)\n",
    "        \n",
    "        # Get Reconstructions\n",
    "        reconstructions = []\n",
    "        with torch.no_grad():\n",
    "            for data in datasets:\n",
    "                latent = model(data)\n",
    "                recon = model.reverse(latent)\n",
    "                reconstructions.append(recon)\n",
    "        \n",
    "        # Calculate Cosine Similarity Matrix\n",
    "        n_ds = len(datasets)\n",
    "        sim_matrix = np.zeros((n_ds, n_ds))\n",
    "        for i in range(n_ds):\n",
    "            for j in range(n_ds):\n",
    "                vec_i = reconstructions[i].view(1, -1)\n",
    "                vec_j = reconstructions[j].view(1, -1)\n",
    "                sim_matrix[i, j] = F.cosine_similarity(vec_i, vec_j).item()\n",
    "\n",
    "        # Plotting Setup for this Row\n",
    "        axs = subfigs[idx].subplots(1, 4, gridspec_kw={'width_ratios': [1, 1, 1, 1]})\n",
    "        subfigs[idx].subplots_adjust(top=0.8) \n",
    "        \n",
    "        # Determine Row Title based on Scale\n",
    "        if scl < 0.1:\n",
    "            desc = \"Linearized Regime\"\n",
    "        else:\n",
    "            desc = \"Full Reconstruction Regime\"\n",
    "            \n",
    "        subfigs[idx].suptitle(f\"SCALE: {scl} ({desc}) - Dim: {dim}\", fontsize=16, fontweight='bold', color='darkblue')\n",
    "\n",
    "        # -----------------------------\n",
    "        # A. Heatmap\n",
    "        # -----------------------------\n",
    "        sns.heatmap(sim_matrix, annot=True, fmt=\".3f\", cmap=\"Blues\", \n",
    "                    xticklabels=labels, yticklabels=labels,\n",
    "                    ax=axs[0], cbar=False, vmin=0, vmax=1)\n",
    "        axs[0].set_title(\"Cosine Similarity Matrix\")\n",
    "        \n",
    "        # -----------------------------\n",
    "        # Helper for Overlays\n",
    "        # -----------------------------\n",
    "        def plot_overlay(ax, idx1, idx2, color1, color2, title_prefix):\n",
    "            d1 = reconstructions[idx1].cpu().numpy()\n",
    "            d2 = reconstructions[idx2].cpu().numpy()\n",
    "            \n",
    "            # Using alpha to show overlap clearly\n",
    "            ax.scatter(d1[:,0], d1[:,1], s=2, c=color1, alpha=0.4, label=full_labels[idx1])\n",
    "            ax.scatter(d2[:,0], d2[:,1], s=2, c=color2, alpha=0.4, label=full_labels[idx2])\n",
    "            \n",
    "            sim_val = sim_matrix[idx1, idx2]\n",
    "            ax.set_title(f\"{title_prefix}\\nSim: {sim_val:.4f}\")\n",
    "            \n",
    "            # Smart Legend placement\n",
    "            ax.legend(loc='upper right', fontsize='x-small', markerscale=3)\n",
    "            ax.axis('equal')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        # -----------------------------\n",
    "        # B. Same Class (Spiral Clean vs Noisy)\n",
    "        # -----------------------------\n",
    "        plot_overlay(axs[1], 0, 1, 'blue', 'cyan', \"MATCH: Same Figure\")\n",
    "\n",
    "        # -----------------------------\n",
    "        # C. Different Class (Spiral vs Circle - Clean)\n",
    "        # -----------------------------\n",
    "        plot_overlay(axs[2], 0, 2, 'blue', 'red', \"MISMATCH: Distinct Figures\")\n",
    "        \n",
    "        # -----------------------------\n",
    "        # D. Different Class (Spiral vs Circle - Noisy)\n",
    "        # -----------------------------\n",
    "        plot_overlay(axs[3], 1, 3, 'cyan', 'orange', \"MISMATCH: Distinct (Noisy)\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    seed_everything(42)\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    run_extended_experiment()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
